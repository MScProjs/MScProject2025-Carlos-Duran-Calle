% The document class supplies options to control rendering of some standard
% features in the result.  The goal is for uniform style, so some attention 
% to detail is *vital* with all fields.  Each field (i.e., text inside the
% curly braces below, so the MEng text inside {MEng} for instance) should 
% take into account the following:
%
% - author name       should be formatted as "FirstName LastName"
%   (not "Initial LastName" for example),
% - supervisor name   should be formatted as "Title FirstName LastName"
%   (where Title is "Dr." or "Prof." for example),
% - degree programme  should be "BSc", "MEng", "MSci", "MSc" or "PhD",
% - dissertation title should be correctly capitalised (plus you can have
%   an optional sub-title if appropriate, or leave this field blank),
% - dissertation type should be formatted as one of the following:
%   * for the MEng degree programme either "enterprise" or "research" to
%     reflect the stream,
%   * for the MSc  degree programme "$X/Y/Z$" for a project deemed to be
%     X%, Y% and Z% of type I, II and III.
% - year              should be formatted as a 4-digit year of submission
%   (so 2014 rather than the academic year, say 2013/14 say).

\documentclass[ % the name of the author
                    author={Carlos Duran Calle},
                % the name of the supervisor
                supervisor={Dr. Felipe Campelo},
                % the degree programme
                    degree={MSc},
                % the dissertation    title (which cannot be blank)
                     title={Comparative Machine Learning Analysis for Student Dropout Prediction in a Virtual Learning Environment},
                % the dissertation subtitle (which can    be blank)
                  subtitle={Incorporating Student Engagement and Socio-Economic Features},
                % the dissertation     type
                      type={},
                % the year of submission
                      year={2025}]{dissertation}

\begin{document}

% =============================================================================

% This section simply introduces the structural guidelines.  It can clearly
% be deleted (or commented out) if you use the file as a template for your
% own dissertation: everything following it is in the correct order to use 
% as is.

%\section*{Prelude}
%\thispagestyle{empty}






% =============================================================================

% This macro creates the standard UoB title page by using information drawn
% from the document class (meaning it is vital you select the correct degree 
% title and so on).


\maketitle

% After the title page (which is a special case in that it is not numbered)
% comes the front matter or preliminaries; this macro signals the start of
% such content, meaning the pages are numbered with Roman numerals.

\frontmatter

% This macro creates the standard UoB declaration; on the printed hard-copy,
% this must be physically signed by the author in the space indicated.

\makedecl

% LaTeX automatically generates a table of contents, plus associated lists 
% of figures, tables and algorithms.  The former is a compulsory part of the
% dissertation, but if you do not require the latter they can be suppressed
% by simply commenting out the associated macro.

\tableofcontents
\listoffigures
\listoftables
\listofalgorithms
`%\lstlistoflistings

% The following sections are part of the front matter, but are not generated
% automatically by LaTeX; the use of \chapter* means they are not numbered.

% -----------------------------------------------------------------------------

\chapter*{Abstract}

{\bf A compulsory section, of at most $1$ page} 
\vspace{1cm} 

\noindent
This section should summarise the project context, aims and objectives,
and main contributions (e.g., deliverables) and achievements.  The goal is to ensure that the 
reader is clear about what the topic is, what you have done within this 
topic, {\em and}\/ {\bf what your view of the outcome is.}

Essentially 
this section is a (very) short version of what is typically covered in more depth in the first 
chapter.  If appropriate, you should include here  
a clear statement of your research hypothesis.  This will obviously differ significantly
for each project, but an example might be as follows:

\begin{quote}
My research hypothesis is that a suitable genetic algorithm will yield
more accurate results (when applied to the standard ACME data set) than 
the algorithm proposed by Jones and Smith, while also executing in less
time.
\end{quote}

\noindent
The latter aspects should (ideally) be presented as a concise, factual 
list of the main points of achievement.  Again the points will differ for each project, but 
an might be as follows:

\begin{quote}
\noindent
\begin{itemize}
\item I spent $120$ hours collecting material on and learning about the 
      Java garbage-collection sub-system. 
\item I wrote a total of $5000$ lines of {\em Python} source code, and associated orchestration scripts. 
\item I designed a new algorithm for computing the non-linear mapping 
      from A-space to B-space using a genetic algorithm.
\item I implemented a version of the algorithm proposed by Jones and 
      Smith (2010), corrected a mistake in it, and 
      compared the results with several alternatives.
\end{itemize}
\end{quote}

% -----------------------------------------------------------------------------

%\chapter*{Summary of Changes}

%{\bf A conditional section, of at most $1$ page} 
%\vspace{1cm} 
%
%If (and only if) the dissertation represents a resubmission (e.g., as the result of
%a resit), then this section is compulsory: the content should summarise all
%non-trivial changes made to the initial submission.  Otherwise you can
%omit it, since {\bf a summary of this type is only needed for resubmissions}.
%
%When included, the section will ideally be used to highlight additional
%work completed, and address criticism raised in any associated feedback.
%Clearly it is difficult to give generic advice about how to do so, but
%an example might be as follows:
%
%\begin{quote}
%\noindent
%\begin{itemize}
%\item Feedback from the initial submission criticised the design and 
%      implementation of my genetic algorithm, stating ``there seems 
%      to have been no attention to computational complexity during the
%      design, and obvious methods of optimisation are missing within
%      the resulting implementation''.  Chapter 3 now includes a
%      comprehensive analysis of the algorithm, in terms of both time
%      and space.  While I have not altered the algorithm itself, I
%      have included a cache mechanism (also detailed in Chapter 3)
%      that provides a significant improvement in average run-time.
%\item I added a feature in my implementation to allow automatic rather
%      than manual selection of various parameters; the experimental
%      results in Chapter 4 have been updated to reflect this.
%\item Questions after the presentation highlighted a range of related
%      work that I had not considered: I have make a number of updates 
%      to Chapter 2, resolving this issue.
%\end{itemize}
%\end{quote}

% -----------------------------------------------------------------------------

\chapter*{Supporting Technologies}

{\bf A compulsory section, of at most $1$ page}
\vspace{1cm} 

\noindent
This section should present a detailed summary, in bullet point form, 
of any third-party resources (e.g., hardware and software components) 
used during the project.  Use of such resources is always perfectly 
acceptable: the goal of this section is simply to be clear about how
and where they are used, so that a clear assessment of your work can
result.  The content can focus on the project topic itself (rather,
for example, than including ``I used \mbox{\LaTeX} to prepare my 
dissertation''); an example is as follows:

\begin{quote}
\noindent
\begin{itemize}

\item I used the {\em Pandas} and {\em Seaborn} public-domian Python Libraries. 

\item I used a parts of the OpenCV computer vision library to capture 
      images from a camera, and for various standard operations (e.g., 
      threshold, edge detection).

\item I used Amazon Web Services for remote storage and processing of data. Specifically, I used:
 \begin{itemize}
 \item Simple Storage Service (S3) for data storage
 \item Elastic Compute Cloud (EC2) for provision of virtual machines
 \item Elastic Beanstalk for scaling and load management
 \item Sagemaker for all the machine learning components of my project. 
 \end{itemize}
 
\item I used \LaTeX\ to format my thesis, via the desktop service {\em TeXstudio}. 
\end{itemize}
\end{quote}

% -----------------------------------------------------------------------------

\chapter*{Notation and Acronyms}

%{\bf An optional section, of roughly $1$ or $2$ pages}
\vspace{1cm} 

%\noindent
%Any well written document will introduce notation and acronyms before
%their use, {\em even if} they are standard in some way: this ensures 
%any reader can understand the resulting self-contained content.  
%
%Said introduction can exist within the dissertation itself, wherever 
%that is appropriate.  For an acronym, this is typically achieved at 
%the first point of use via ``Advanced Encryption Standard (AES)'' or 
%similar, noting the capitalisation of relevant letters.  However, it 
%can be useful to include an additional, dedicated list at the start 
%of the dissertation; the advantage of doing so is that you cannot 
%mistakenly use an acronym before defining it.  A limited example is 
%as follows:

\begin{quote}
\noindent
\begin{tabular}{lcl}
SDP                 &:     & Student Dropout Predictor	\\
MOOCs               &:     & Massive Open Online Courses	\\
VLEs                &:     & Virtual Learning Environments	\\
OULAD               &:     & Open University Learning Analytics Dataset	\\
ML                  &:     & Machine Learning	\\
RF                  &:     & Random Forest	\\
LG                  &:     & Logistic Regression	\\
LightGBM            &:     & Light Gradient-Boosting Machine	\\
NNs                 &:     & Neural Networks	\\
SE                  &:     & Student Engagement	\\
KNN                 &:     & K-Nearest Neighbors	\\
KNN                 &:     & K-Nearest Neighbors	\\
KNN                 &:     & K-Nearest Neighbors	\\
KNN                 &:     & K-Nearest Neighbors	\\
KNN                 &:     & K-Nearest Neighbors	\\
KNN                 &:     & K-Nearest Neighbors	\\
%                    &\vdots&                                                                      \\
%${\mathcal H}( x )$ &:     & the Hamming weight of $x$                                            \\
%${\mathbb  F}_q$    &:     & a finite field with $q$ elements                                     \\
$x_i$               &:     & the $i$-th bit of some binary sequence $x$, st. $x_i \in \{ 0, 1 \}$ \\
\end{tabular}
\end{quote}

% -----------------------------------------------------------------------------

\chapter*{Acknowledgements}

{\bf An optional section, of at most $1$ page}
\vspace{1cm} 

\noindent
It is common practice (although totally optional) to acknowledge any
third-party advice, contribution or influence you have found useful
during your work.  Examples include support from friends or family, 
the input of your Supervisor and/or Advisor, external organisations 
or persons who  have supplied resources of some kind (e.g., funding, 
advice or time), and so on.

\vspace{1cm}
Dave Cliff writes here to say huge thanks to his colleague Dr Dan Page for sharing this \LaTeX\ thesis template, which was originally written by Dan, for Computer Science dissertations. Dave edited Dan's original to better suit the needs of the Data Science MSc: please don't hassle Dan about any of this, but do feel free to contact Dave if you have any questions or comments on it.  

% =============================================================================

% After the front matter comes a number of chapters; under each chapter,
% sections, subsections and even subsubsections are permissible.  The
% pages in this part are numbered with Arabic numerals.  Note that:
%
% - A reference point can be marked using \label{XXX}, and then later
%   referred to via \ref{XXX}; for example Chapter\ref{chap:context}.
% - The chapters are presented here in one file; this can become hard
%   to manage.  An alternative is to save the content in seprate files
%   the use \input{XXX} to import it, which acts like the #include
%   directive in C.

\mainmatter

% -----------------------------------------------------------------------------

\chapter{Introduction}
\label{chap:introduction}

%{\bf A compulsory chapter, roughly 10\% of the total page-count}
\vspace{1cm} 

% putting a \noindent before the first para in each chapter looks nicer.
\noindent
%This chapter should describe the project context, and motivate each of
%the proposed aims and objectives.  Ideally, it is written at a fairly 
%high-level, and easily understood by a reader who is technically 
%competent but not an expert in the topic itself.
%
%In short, the goal is to answer three questions for the reader.  First, 
%what is the project topic, or problem being investigated?  Second, why 
%is the topic important, or rather why should the reader care about it?  
%For example, why there is a need for this project, who will benefit from the 
%project and in what way (e.g., clients/end-users who needed some analysis
%done, or other data scientists who might need the tools you have developed), what 
%work does the project build on and why is the selected approach either
%important and/or interesting (e.g., fills a gap in literature, applies
%results from another field to a new problem).  Finally, what are the 
%central challenges involved and why are they significant? 
The rise of online learning environments, such as Massive Open Online Courses (MOOCs) and Virtual Learning Environments (VLEs), has transformed the educational landscape, providing unprecedented access to education for diverse populations \cite{maiz_olazabalaga_research_2016}. However, despite these advancements, a significant challenge persists: a high dropout rate among students. Research indicates that approximately $78\%$ of students enrolled in online courses do not complete their studies, primarily due to a lack of face-to-face interaction \cite{simpson_can_we_do_better}. Another study states that the main reason for withdrawal from VLEs is the lack of student engagement, followed by the inability to locate materials or activities for assessments \cite{kuzilek_ou_2015}. Therefore, student engagement is a key area of research, as low engagement negatively impacts final grades, knowledge retention, and dropout rates \cite{staikopoulos_SE_2015}. In VLEs, the more students engage in meaningful activities, the higher the probability that they will enjoy the course, perform well, and complete it \cite{jung_learning_2018}.

This project aims to address the problem by applying machine learning (ML) models, comparing them, and selecting the best one as part of the Student Dropout Predictor (SDP). For this purpose, data from the Open University Learning Analytics Dataset (OULAD) is used \cite{kuzilek_OULAD_2017}. The Open University, the largest in the UK, offers over a thousand online courses and provides full online degree programs \cite{hlosta_modellingVLE_2018}.

This alarming statistic underscores the urgent need to develop effective strategies for early prediction and mitigation of student dropout, enabling timely support that can help learners stay engaged and successfully complete their courses.

\section{ML Models for Predictions}
ML, a part of artificial intelligence, allows computer programs to automatically find complex patterns in features taken from existing data. This helps in making smart decisions about new data \cite{holland_ML_1992}. ML algorithms are trained on sample data and later evaluated with unseen data \cite{kotsiantis_2004}. This type of ML, where the algorithm learns a mapping function from input variables (features) to an output variable (label) using labelled training data, is known as Supervised Learning \cite{murphy_ml_2012}. ML algorithms can provide instructors with real-time insights about students, enabling early interventions during the course \cite{kai_2017}. ML is widely applied to develop predictive models from student data, handling both numerical and categorical variables to effectively model student behaviours and outcomes \cite{baker_educational_2014}. 

This project conducts a comparative evaluation of six ML models: Random Forest (RF), Logistic Regression (LR), K-Nearest Neighbors (KNN), LightGBM, Support Vector Machine (SVM), and Neural Networks (NNs). Each model is assessed on its ability to classify student outcomes into the discrete labels ‘Withdrawn’ (0), ‘Fail’ (1), or ‘Pass’ (2), with particular emphasis on accurately identifying the ‘Withdrawn’ class. For example, RF is known for its robustness and ability to handle large datasets with high dimensionality \cite{breiman_rf_2001}, while LightGBM is optimized for speed and efficiency, making it suitable for large-scale applications \cite{friedman_gbm_2001}. LR offers interpretable results \cite{harrell_LR_2015}, KNN captures local data patterns, SVM performs well in high-dimensional spaces \cite{cortes_svm_1995}, and NNs can model complex relationships \cite{lecun_nn_gradient-applied_1998}. Supervised learning algorithms can be divided into classifiers and regressors, where the previously ML models mentioned, when used as classifiers, serve to predict discrete class labels \cite{geron_oreilly_2019}.

The primary evaluation metric will be recall for the 'Withdrawn' class (0), as this reflects the model’s ability to correctly identify students who have dropped out. Maximizing recall for this minority class is critical to ensure timely support and intervention. Given the imbalanced nature of the classification problem, focusing on dropout recall helps prevent overlooking students who need immediate assistance \cite{sokolova_classification_tasks_2009}. The comparative analysis aims to identify which model achieves the highest recall for the 'Withdrawn' class, thereby determining the most effective approach for dropout detection.

\section{Research Objectives}
Using data from the Open University Learning Analytics Dataset (OULAD), the study will evaluate how well each model detects withdrawal cases, with a focus on maximizing recall for this class. Additionally, the project incorporates a 'Student Engagement' variable \cite{hussain_student_engagement_prediction_2018} and socio-economic factors such as the deprivation index to enrich the analysis of factors influencing student withdrawal.

Student engagement will be measured as a simple yes/no (binary) variable, following the method described by Mushtaq et al. \cite{hussain_student_engagement_prediction_2018}. This variable will be calculated using information such as scores on course assignments, whether the student passed or failed the course, and how active the student was in the virtual learning environment (VLE).

%\paragraph{}
\noindent
The specific objectives of this project are:
\begin{itemize}
	\item To incorporate the student engagement feature as a meaningful predictor for the machine learning models.
	\item To identify which socio-demographic variables are meaningfully linked to student dropout.
	\item To select a predictive model capable of identifying students likely to withdraw at early stages of their course.
\end{itemize}

Earlier studies that used OULAD data, such as those by Tomasevic et al. \cite{tomasevic_comparison_supervised_data_2020} and Hussain et al. \cite{hussain_student_engagement_prediction_2018}, have looked at student engagement and predicted student dropout. However, these studies did not fully examine which demographic variables showed stronger connections with dropout. The main reason for this project is to provide useful insights into the importance of demographic variables by improving the student dropout model with the addition of student engagement data. Additionally, this project will include the timing of assessments to help make predictions at an early stage of the course. Adding this analysis aims to offer another way to improve models that predict student dropout. For this project, the prediction results will be grouped into three classes: 'Withdrawal' (0), 'Fail' (1), or 'Pass' (2).

\section{Significance and Contributions}
The importance of this project extends beyond academic curiosity; it has practical implications for educators, administrators, and policymakers. By accurately predicting student dropout, institutions can implement timely interventions, tailor support services, and improve course designs, ultimately leading to higher retention rates and better educational outcomes \cite{kahu_student_engagement_2013}. Additionally, the insights gained from this research will benefit data scientists and educational technologists by providing a framework for developing predictive tools that can be applied across various educational contexts.

This project builds on existing literature that has explored student engagement and dropout prediction using machine learning techniques \cite{tomasevic_comparison_supervised_data_2020, hussain_student_engagement_prediction_2018}. However, it seeks to fill a critical gap by integrating demographic variables and engagement metrics into a comprehensive predictive model. The selected approach is significant as it not only addresses the immediate problem of dropout prediction but also contributes to the broader discourse on enhancing student engagement in VLEs.

\section{Challenges}
Central challenges in this endeavour include ensuring the accuracy and reliability of the predictive models, addressing potential biases in the data, and effectively measuring student engagement at various stages of the learning process. These challenges are significant as they directly impact the validity of the predictions and the effectiveness of subsequent interventions. By tackling these issues, this project aims to provide valuable insights that can inform future research and practice in the field of online education.

\paragraph{}
%\noindent
In summary, this project focuses on performing and comparing six machine learning models to identify the best-performing model for detecting students who have withdrawn from online courses. By emphasizing recall for the 'Withdrawn' class and incorporating engagement and socio-economic factors, the study aims to provide actionable insights that support timely interventions and improve student retention in virtual learning environments. 
%The chapter should conclude with a concise bullet point list that 
%summarises the aims, objectives, {\bf and achievements}\/ of your work. 

% -----------------------------------------------------------------------------

\chapter{Technical Background}
\label{chap:background}

%{\bf A compulsory chapter, roughly 20\% of the total page-count}
\vspace{1cm} 

\noindent
This chapter contains the technical background for the comparison of machine learning models in terms of student dropout predictions. It offers critical concepts, such as educational data mining, the class imbalance problem, and the conceptual principles that underlie classic algorithms, such as ensemble methods, linear classifiers, and neural networks. The chapter ends with brief discussions about important model evaluation and feature engineering methods.

\section{Educational Data Mining in VLEs}
Educational Data Mining in VLEs explores the wealth of behavioural data produced by students (ie, clickstream patterns and resource access statistics) for the purpose of gaining knowledge on how they learn \cite{romero_data_2013}. Browsing and resource navigation behaviour have been shown to be strong predictors of academic performance, such as course completion \cite{gasevic_learning_2016}. Combining this behavioural data with a learners' demographics and assessment results substantially enhances prediction accuracy of dropout models \cite{viberg_current_2018}.

The temporal nature of this data is important. Early warning signs of at-risk students can be well-predicted from early-stage behaviour patterns \cite{conijn_predicting_2017}. The high-frequency of VLE data streams on the other hand requires advanced preprocessing to deal with missing values, irregular sampling intervals, and varying engagement patterns across different student populations \cite{sclater_learning_2016}. In addition, integrating VLE interaction data with socio-economic features improves model stability and classification performance, and paves the way for a more systematic feature engineering in educational prediction systems \cite{hlosta_modellingVLE_2018}.

\section{Multi-Class Classification}
In education, multi-class classification is complicated since the standard binary techniques are not effective in modelling the interactions among various performance levels, which leads to specialized algorithms \cite{fernandez_learning_2018}. Model collection is in turn influencing the ordinal nature of effects (e.g., from “Pass to Fail”) might need attentive attention at some stage in model training \cite{liu_exploratory_2009}. Standard decomposition methods may bias such type of ordered data, which validate why it is useful to apply native multi-class algorithms in order to predict student performances accurately \cite{krawczyk_learning_2016}.

Class imbalance is a critical challenge in educational data, as traditional accuracy metrics can be misleading by failing to reflect poor performance on key minority classes, such as "Withdrawn" students \cite{haixiang_learning_2017}. Proper evaluation of these models requires specialized metrics, such as class-specific recall and macro-averaged F1 scores, to ensure a balanced assessment \cite{luque_impact_2019}. Advanced techniques, including strategic oversampling combined with ensemble methods, have been shown to significantly improve the identification of these at-risk students \cite{galar_review_2012}.

\section{Multi-Class Evaluation Metrics}
The class-specific performance metrics can offer valuable insights on how a model performs and work well for imbalanced data. Among these, precision and recall are core indicators for assessment of classification effectiveness. For a given class $i$, precision is defined as the ratio of true positive predictions to all positive predictions, as shown in Equation 2.1. This concept is introduced in \cite{sokolova_classification_tasks_2009}.
\begin{equation}
	\text{Precision}_{i} = \frac{TP_{i}}{TP_{i} + FP_{i}}
	\tag{2.1}
\end{equation}
\begin{center}
	where $TP_{i}$ represents true positives and $FP_{i}$ represents false positives for class $i$.
\end{center}

On the other hand, recall is defined as the ratio of the actual positive instances that are classified as positive which is given in Equation 2.2 \cite{sokolova_classification_tasks_2009}. In educational applications, recall for the "Withdrawn" class is especially important as it measures the model's capacity to detect students who need early support, while having high recall rates ensures that such at-risk students are not missed out even with elevated false positive rates \cite{grandini_metrics_2020}.
\begin{equation}
	\text{Recall}_{i} = \frac{TP_{i}}{TP_{i} + FN_{i}}
	\tag{2.2}
\end{equation}
\begin{center}
	where $TP_{i}$ represents true positives and $FN_{i}$ denotes false negatives for class $i$.
\end{center}

Weighted metrics compensate for the class imbalance by incorporating the relative frequency of each class contributing to the overall performance measure and deliver a model effectiveness evaluation that is more representative of how well it generalizes to all categories \cite{jeni_facing_2013}. Weighted recall is calculated according to the Equation 2.3 \cite{tantisripreecha_novel_2022}.
\begin{equation}
	\text{Weighted Recall} = \sum_{i} w_{i} \times \text{Recall}_{i}
	\tag{2.3}
\end{equation}
\begin{center}
	where $w_{i}$ is the weight for class $i$, usually based on its frequency in the dataset.
\end{center}

Weighted F1-score is the harmonic mean of precision and recall for each class $i$ \cite{tantisripreecha_novel_2022} \cite{opitz_closer_2024} as in the Equation 2.4. These balanced metrics allow us to measure the performance level for all categories of evaluation indicators while still being sensitive to the practical important of minority class detection in the educational intervention systems \cite{krawczyk_learning_2016}.
\begin{equation}
	\text{Weighted F1} = \sum_{i} w_{i} \times F1_{i}
	\tag{2.4}
\end{equation}
\begin{center}
	where $F1_{i} = 2 \times \frac{\text{Precision}_{i} \times \text{Recall}_{i}}{\text{Precision}_{i} + \text{Recall}_{i}}$ 
	and $w_{i}$ represents the weight assigned to class $i$.
\end{center}

\section{Strategies for Imbalanced Data}
Balanced class weight is one of the basic approaches to address the imbalance of the dataset where the importance of each class is adjusted automatically and inversely proportional to the frequency of that class and the mathematical foundation is given as it is written in the Equation 2.5 \cite{akor_hierarchical_2025}.
\begin{equation}
	w_{i} = \frac{n_{\text{samples}}}{n_{\text{classes}} \times n_{\text{samples}_{i}}}
	\tag{2.5}
\end{equation}
\begin{center}
	where $w_{i}$ denotes the weight for class $i$, $n_{\text{samples}}$ represents the total number of samples, 
	$n_{\text{classes}}$ indicates the number of classes, and $n_{\text{samples}_{i}}$ represents the number of samples in class $i$.
\end{center}

Customized scoring metrics deepen this approach by considering domain-specific preferences, by dropout-specific optimization forcing the maximization of the recall for withdrawal detection via biasing the learning criterion in favour of at-risk students and focusing less on false negatives \cite{orooji_predicting_2019}.

Early warning signs do exist to prevent high-risk youngsters and to intervene early. In the context of dropout prediction, the imbalance class is the minority dropout class, which results in heavy emphasize on recall to detect the dropout students for timely intervention \cite{lee_machine_2019}. Unbalanced-learning techniques (e.g., resampling or class weighting) generally improve recall for the rare class (dropout) at the expense of precision \cite{orooji_predicting_2019}, which is the same precision-recall trade-off this work aims to find the best level of.

In the area of dropout early-detection, balancing the class distribution among minority and majority instances should be considered desirably by using class weights, which disadvantage the majority and advantage the minority class, e.g., the weight of the minority class being higher than $1$ and the weight of the majority class being equal to $1$ is common \cite{hlosta_ouroboros_2017}. More recent losses, e.g., the Class-Balanced Loss, have tried to provide a more principled re-weighting beyond naïve inverses only when classes are long-tailed \cite{cui_class-balanced_2019}. For the current study it is beneficial as we would like to investigate alternative to ad-hoc multipliers, used for balanced weighting, like x$1.2$ for the minority class “Withdrawn” and x$0.8$ for the majority class “Pass”. The multipliers are domain specific choices of the experimentations: there is one setting that uses no multipliers (balanced weighting), and one that applies the multipliers. Lastly, note that overall accuracy may be deceptive of imbalanced data, as Precision and Recall can better assess minority-class detection quality \cite{saito_precision-recall_2015}.

\section{ML Algorithms for SDP}
Ensemble learning exploits multiple models to reduce variance and improve generalization; in Random Forests, bootstrap aggregation (bagging) draws resamples of the training set and averages randomized decision trees, providing robustness and out‑of‑bag error estimation \cite{breiman_bagging_1996} \cite{breiman_rf_2001}. Feature importance in RF is commonly derived from impurity decreases or permutation‑based accuracy drops, enabling screening of influential predictors in heterogeneous educational data \cite{breiman_rf_2001}. Gradient‑boosting frameworks fit weak learners sequentially under an additive model to minimize a differentiable loss, while LightGBM accelerates this process using histogram‑based splits, leaf‑wise growth, and gradient‑based one‑side sampling for scalability on high‑dimensional, large cohorts \cite{friedman_gbm_2001} \cite{ke_lightgbm_2017}. Logistic Regression models the log‑odds of class membership and estimates coefficients by maximum likelihood, yielding interpretable effects as odds ratios and supporting regularization for stability when features are correlated \cite{cox_regression_1958} \cite{nelder_generalized_1972}. Support Vector Machines maximize the geometric margin via convex quadratic programming and use kernel mappings to induce flexible non‑linear decision boundaries while controlling capacity through the margin and kernel parameters \cite{cortes_svm_1995}. 

Instance‑based learning with K‑Nearest Neighbors classifies by a majority (plurality) vote among the K closest samples, so decision boundaries are local and sensitive to the choice of distance metric and K, with common metrics including Euclidean, Manhattan, and Mahalanobis distances \cite{cover_nearest_1967} \cite{aha_instance-based_1991}. Multi‑layer perceptrons compose affine transformations with non‑linear activations and are trained end‑to‑end by backpropagation to minimize a supervised loss, with universal approximation guaranteeing expressive capacity under sufficient width or depth \cite{rumelhart_learning_1986} \cite{hornik_multilayer_1989}. These foundations motivate comparing Random Forests, LightGBM, Logistic Regression, SVMs, KNN, and MLPs for dropout prediction, balancing interpretability, non‑linear modeling power, and computational efficiency under class imbalance typical of at‑risk cohorts \cite{krawczyk_learning_2016}.

\section{Model Evaluation and Comparison Methodologies}
Performance was estimated with stratified 5‑fold cross‑validation \cite{kohavi_study_1995} on the training split to preserve class proportions and reduce variance in imbalanced data, with a fixed stratified train–test split reused for all models to ensure comparability \cite{luque_impact_2019}. Hyperparameter search was executed within cross‑validation (GridSearchCV) and final metrics were computed once on the untouched test split to limit selection bias \cite{varma_bias_2006}. All models were evaluated on identical folds and scoring rules to enable fair, paired comparisons across the pipeline \cite{demsar_statistical_2006}. Hyperparameters were optimized via exhaustive GridSearchCV with five folds, parallel execution, dropout‑recall as the objective, and class‑weighting to emphasize minority cases \cite{kohavi_study_1995} \cite{krawczyk_learning_2016}.

Regularisation and early stopping are treated as crucial mechanisms to curb over‑fitting and stabilise learning dynamics \cite{prechelt_early_2012}. In LR, the strength of regularisation is controlled by the inverse‑penalty parameter $C$, with $L1/L2$ penalties shaping sparsity and shrinkage behaviour \cite{ng_feature_2004}. For SVM, the soft‑margin constant $C$ and kernel scale gamma are tuned to balance margin violations and function smoothness \cite{cortes_svm_1995}. In decision trees and ensemble methods, maximum depth and the number of estimators are adjusted to limit variance and improve robustness \cite{breiman_rf_2001}. In gradient boosting, the learning rate and number of boosting rounds jointly govern additive model capacity and error reduction \cite{friedman_gbm_2001}. For KNN, the neighbourhood size $k$ and the choice of distance metric determine locality and boundary smoothness \cite{cover_nearest_1967}. In multilayer perceptrons, hidden‑layer size and weight decay are set under backpropagation to control capacity and enhance generalisation \cite{krogh_simple_1991}. 






%\noindent
%But if you prefer to use a more concise structure, you could instead use:
%\begin{enumerate}
%\item Introduction: Contextual Background
%\item Technical Background
%\end{enumerate}
%\noindent


%The key thing is that by the end of these first two or three chapters you have told the reader everything they need to know so that they can understand the rest of your thesis. This is particularly important because at least one of the people who actually examines your thesis will be a UoB academic, one of our lecturers or professors, who you can assume knows almost nothing about the specifics of what work you have done, and who is given a copy of your thesis to mark. So what you write has to adequately explain things to that examiner. You can safely assume that whoever examines your thesis is numerate, intelligent, understands programming and data analytics etc, but you cannot safely assume that their specific individual expertise is a perfect match to the topic of your thesis (it's in that sense that the examiner is a {\em non-expert}). So, the person you write for, your {\em audience}, should be that undefined group of academics who might possibly examine your thesis: if you write for that audience and do a good job, your thesis should be understandable by a wide range of people, including potential employers and colleagues in the world of work.

% -----------------------------------------------------------------------------

\chapter{Execution}
\label{chap:execution}

{\bf A topic-specific chapter, roughly 30\% of the total page-count}
\vspace{1cm} 

\noindent
This chapter is intended to describe what you did: the goal is to explain
the main activity or activities, of any type, which constituted your work 
during the project.  The content is highly topic-specific. For some 
projects it will make sense to split the content into two main sections, or maybe even into two separate chapters: one 
will discuss the design of something, including any rationale or decisions made, 
and the other will discuss how this design was realised via some form of 
implementation.  You could instead give this chapter the title ``Design and Implementation"; or you might split this content into two chapters, one titled ``Design" and the other ``Implementation" .

Note that it is common to include evidence of ``best practice'' project 
management (e.g., use of version control, choice of programming language 
and so on).  Rather than simply a rote list, make sure any such content 
is useful and/or informative in some way: for example, if there was a 
decision to be made then explain the trade-offs and implications 
involved.

\section{Example Section}

This is an example section; 
the following content is auto-generated dummy text.
\lipsum

\subsection{Example Sub-section}

\begin{figure}[t]
\centering
foo
\caption{This is an example figure.}
\label{fig}
\end{figure}

\begin{table}[t]
\centering
\begin{tabular}{|cc|c|}
\hline
foo      & bar      & baz      \\
\hline
$0     $ & $0     $ & $0     $ \\
$1     $ & $1     $ & $1     $ \\
$\vdots$ & $\vdots$ & $\vdots$ \\
$9     $ & $9     $ & $9     $ \\
\hline
\end{tabular}
\caption{This is an example table.}
\label{tab}
\end{table}

\begin{algorithm}[t]
\For{$i=0$ {\bf upto} $n$}{
  $t_i \leftarrow 0$\;
}
\caption{This is an example algorithm.}
\label{alg}
\end{algorithm}

\begin{lstlisting}[float={t},caption={This is an example listing.},label={lst},language=C]
for( i = 0; i < n; i++ ) {
  t[ i ] = 0;
}
\end{lstlisting}

This is an example sub-section;
the following content is auto-generated dummy text.
Notice the examples in Figure~\ref{fig}, Table~\ref{tab}, Algorithm~\ref{alg}
and Listing~\ref{lst}.
\lipsum

\subsubsection{Example Sub-sub-section}

This is an example sub-sub-section;
the following content is auto-generated dummy text.
\lipsum

\paragraph{Example paragraph.}

This is an example paragraph; note the trailing full-stop in the title,
which is intended to ensure it does not run into the text.

% -----------------------------------------------------------------------------

\chapter{Critical Evaluation}
\label{chap:evaluation}

{\bf A topic-specific chapter, roughly 30\% of the total page-count} 
\vspace{1cm} 

\noindent
This chapter is intended to evaluate what you did.  The content is highly 
topic-specific, but for many projects will have flavours of the following:

\begin{enumerate}
\item functional  testing, including analysis and explanation of failure 
      cases,
\item behavioural testing, often including analysis of any results that 
      draw some form of conclusion wrt. the aims and objectives,
      and
\item evaluation of options and decisions within the project, and/or a
      comparison with alternatives.
\end{enumerate}

\noindent
This chapter often acts to differentiate project quality: even if the work
completed is of a high technical quality, critical yet objective evaluation 
and comparison of the outcomes is crucial.  In essence, the reader wants to
learn something, so the worst examples amount to simple statements of fact 
(e.g., ``graph X shows the result is Y''); the best examples are analytical 
and exploratory (e.g., ``graph X shows the result is Y, which means Z; this 
contradicts [1], which may be because I use a different assumption'').  As 
such, both positive {\em and}\/ negative outcomes are valid {\em if} presented 
in a suitable manner.

% -----------------------------------------------------------------------------

\chapter{Conclusion}
\label{chap:conclusion}

{\bf A compulsory chapter,  roughly 10\% of the total page-count}
\vspace{1cm} 

\noindent
The concluding chapter(s) of a dissertation are often underutilized because they're 
too often left too close to the deadline: it is important to allocate enough time and 
attention to closing off the story, the narrative, of your thesis.

Again, there is no single correct way of closing a thesis. 

One good way of doing this is to have a single chapter consisting of three parts:

\begin{enumerate}
\item (Re)summarise the main contributions and achievements, in essence
      summing up the content.
\item Clearly state the current project status (e.g., ``X is working, Y 
      is not'') and evaluate what has been achieved with respect to the 
      initial aims and objectives (e.g., ``I completed aim X outlined 
      previously, the evidence for this is within Chapter Y'').  There 
      is no problem including aims which were not completed, but it is 
      important to evaluate and/or justify why this is the case.
\item Outline any open problems or future plans.  Rather than treat this
      only as an exercise in what you {\em could} have done given more 
      time, try to focus on any unexplored options or interesting outcomes
      (e.g., ``my experiment for X gave counter-intuitive results, this 
      could be because Y and would form an interesting area for further 
      study'' or ``users found feature Z of my software difficult to use,
      which is obvious in hindsight but not during at design stage; to 
      resolve this, I could clearly apply the technique of Bloggs {\em et al.}.
\end{enumerate}

Alternatively, you might want to divide this content into two chapters: a penultimate chapter with a title such as ``Further Work" and then a final chapter ``Conclusions". Again, there is no hard and fast rule, we trust you to make the right decision. 

And this, the final paragraph of this thesis template, is just a bunch of citations, added to show how to generate a BibTeX bibliography. Sources that have been randomly chosen to be cited here include:
%\cite{miller_etal_2018_clojure,webber_marwan_2015,touretzky_2013_lisp,eckmann_etal_1987,marwan_2011,vach_2015,shiller_2017,vytelingum_2006,tesfatsion_2002,rust_etal_1992}.




% =============================================================================

% Finally, after the main matter, the back matter is specified.  This is
% typically populated with just the bibliography.  LaTeX deals with these
% in one of two ways, namely
%
% - inline, which roughly means the author specifies entries using the 
%   \bibitem macro and typesets them manually, or
% - using BiBTeX, which means entries are contained in a separate file
%   (which is essentially a database) then imported; this is the 
%   approach used below, with the databased being dissertation.bib.
%
% Either way, the each entry has a key (or identifier) which can be used
% in the main matter to cite it, e.g., \cite{X}, \cite[Chapter 2}{Y}.

\backmatter

%\bibliographystyle{unsrt}
\bibliography{sample_bibtex.bib}

% -----------------------------------------------------------------------------

% The dissertation concludes with a set of (optional) appendices; these are 
% the same as chapters in a sense, but once signalled as being appendices via
% the associated macro, LaTeX manages them appropriately.

\appendix

\chapter{An Example Appendix}
\label{appx:example}

Content which is not central to, but may enhance the dissertation can be 
included in one or more appendices; examples include, but are not limited
to

\begin{itemize}
\item lengthy mathematical proofs, numerical or graphical results which 
      are summarised in the main body,
\item sample or example calculations, 
      and
\item results of user studies or questionnaires.
\end{itemize}

\noindent
Note that in line with most research conferences, the examiners are not
obliged to read such appendices.

% =============================================================================

\end{document}

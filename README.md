# MScProject - Student Assessment Analysis

A comprehensive machine learning analysis system for student performance prediction using demographic data, VLE engagement metrics, and assessment scores.

## ğŸ¯ Project Overview

This project analyzes student performance data to predict academic outcomes using machine learning models. It examines relationships between demographic characteristics, Virtual Learning Environment (VLE) engagement, assessment scores, and final results through multiple classification models.

### Key Research Questions
- How do demographic factors influence student success?
- What is the relationship between VLE engagement and academic performance?
- Which variables are the strongest predictors of student outcomes?
- How do different machine learning models compare in predicting student results?

## ğŸ“ Project Structure

```
MScProject/
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ Data/                               # ğŸ“Š Dataset and processed outputs
â”‚   â”œâ”€â”€ assessments.csv                 # Assessment metadata
â”‚   â”œâ”€â”€ courses.csv                     # Course information
â”‚   â”œâ”€â”€ studentAssessment.csv           # Student assessment scores
â”‚   â”œâ”€â”€ studentInfo.csv                 # Student demographics
â”‚   â”œâ”€â”€ studentRegistration.csv         # Course registration data
â”‚   â”œâ”€â”€ studentVle.csv                  # VLE interaction logs
â”‚   â”œâ”€â”€ vle.csv                         # VLE resource information
â”‚   â”œâ”€â”€ output/                         # ğŸ“ Processed training/test data
â”‚   â”‚   â”œâ”€â”€ processed_data.csv          # Cleaned dataset
â”‚   â”‚   â”œâ”€â”€ X_train_encoded.csv         # Training features
â”‚   â”‚   â”œâ”€â”€ X_test_encoded.csv          # Test features
â”‚   â”‚   â”œâ”€â”€ y_train.csv                 # Training labels
â”‚   â”‚   â””â”€â”€ y_test.csv                  # Test labels
â”‚   â””â”€â”€ model_metrics/                  # ğŸ¤– Model outputs and evaluation
â”‚       â”œâ”€â”€ models/                     # ğŸ“ Trained model files (.pkl)
â”‚       â”‚   â”œâ”€â”€ random_forest_optimized.pkl
â”‚       â”‚   â”œâ”€â”€ multinomial_logistic_regression_optimized.pkl
â”‚       â”‚   â”œâ”€â”€ knn_optimized.pkl
â”‚       â”‚   â”œâ”€â”€ lightgbm_optimized.pkl
â”‚       â”‚   â”œâ”€â”€ svm_optimized.pkl
â”‚       â”‚   â”œâ”€â”€ neural_network_optimized.pkl
â”‚       â”‚   â””â”€â”€ *_scaler.pkl            # Feature scalers for applicable models
â”‚       â”œâ”€â”€ metrics/                    # ğŸ“ Performance metrics (JSON/CSV)
â”‚       â”‚   â”œâ”€â”€ *_metrics.json          # Model performance scores
â”‚       â”‚   â”œâ”€â”€ *_confusion_matrix.json # Confusion matrices
â”‚       â”‚   â”œâ”€â”€ *_coefficients.json     # Model coefficients/feature importance
â”‚       â”‚   â””â”€â”€ *_feature_importance.csv
â”‚       â”œâ”€â”€ reports/                    # ğŸ“ Classification reports (JSON)
â”‚       â””â”€â”€ *_USAGE_INSTRUCTIONS.txt    # Model usage guides
â”‚
â”œâ”€â”€ Documentation/                      # ğŸ“‹ Project documentation
â”‚   â””â”€â”€ Project_Plan-Carlos_Duran.pdf   # Project planning document
â”‚
â”œâ”€â”€ Python_files/                      # ğŸ Core analysis modules
â”‚   â”œâ”€â”€ __init__.py                     # Package initialization
â”‚   â”œâ”€â”€ config_file.py                  # Configuration settings
â”‚   â”œâ”€â”€ data_loader.py                  # Data loading utilities
â”‚   â”œâ”€â”€ data_processor.py               # Data cleaning and preprocessing
â”‚   â”œâ”€â”€ encoding_utils.py               # Feature encoding for ML models
â”‚   â”œâ”€â”€ analysis_engine.py              # Statistical analysis functions
â”‚   â””â”€â”€ visualization.py                # Plotting and visualization tools
â”‚
â”œâ”€â”€ Notebooks/                          # ğŸ““ Analysis workflow notebooks
â”‚   â”œâ”€â”€ 01_data_ingest_cleaning.ipynb           # Data ingestion and cleaning
â”‚   â”œâ”€â”€ 02_visual_analysis.ipynb                # Exploratory data analysis
â”‚   â”œâ”€â”€ 03_data_stratification_encoding.ipynb   # Data preparation for ML
â”‚   â”œâ”€â”€ 04_model_random_forest.ipynb            # Random Forest model
â”‚   â”œâ”€â”€ 05_model_multi_logistic_regression.ipynb # Logistic Regression model
â”‚   â”œâ”€â”€ 06_model_knn.ipynb                      # K-Nearest Neighbors model
â”‚   â”œâ”€â”€ 07_model_lightGBM.ipynb                 # LightGBM model
â”‚   â”œâ”€â”€ 08_model_SVM.ipynb                      # Support Vector Machine model
â”‚   â”œâ”€â”€ 09.model_neural_networks.ipynb          # Neural Network model
â”‚   â””â”€â”€ X1_model_comparison_analysis.ipynb      # Comprehensive model comparison
â”‚
â””â”€â”€ Visualizations/                     # ğŸ“ˆ Generated plots and charts
    â””â”€â”€ Model_comparison/               # ğŸ“ Model comparison visualizations
        â”œâ”€â”€ 01_class_distribution.png          # Target class distribution
        â”œâ”€â”€ 02_model_comparison.png            # Model performance comparison
        â”œâ”€â”€ 03_class_level_performance.png     # Per-class performance metrics
        â””â”€â”€ 04_confusion_matrices.png          # Confusion matrices grid
```

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install pandas numpy matplotlib seaborn plotly scikit-learn jupyter lightgbm
```

### Running the Analysis
1. **Data Setup**: Place CSV files in the `Data/` folder
2. **Complete Pipeline**: Open `Notebooks/01_data_ingest_cleaning.ipynb` and run sequentially through `X1_model_comparison_analysis.ipynb`
3. **Individual Models**: Run specific model notebooks (04-09) for focused analysis
4. **Custom Analysis**: Import modules from `Python_files/` for programmatic use

## ğŸ“Š Models & Results

### Implemented Models
- **Random Forest** - Ensemble tree-based classifier
- **Logistic Regression** - Linear classification with regularization
- **K-Nearest Neighbors** - Instance-based learning
- **LightGBM** - Gradient boosting framework
- **Support Vector Machine** - Kernel-based classification
- **Neural Networks** - Multi-layer perceptron

### Key Features
- **Feature Engineering**: VLE engagement metrics, demographic encoding
- **Model Optimization**: Hyperparameter tuning with cross-validation
- **Performance Evaluation**: Accuracy, precision, recall, F1-score, confusion matrices
- **Feature Importance**: Analysis of predictive factors across models
- **Comprehensive Comparison**: Head-to-head model performance analysis

## ğŸ“ˆ Outputs

### Model Artifacts
- Trained models saved as `.pkl` files
- Feature scalers for models requiring normalization
- Performance metrics in JSON format
- Classification reports with detailed per-class statistics

### Visualizations
- Model performance comparison charts
- Confusion matrices for all models
- Feature importance rankings
- Class distribution analysis

### Data Products
- Processed and encoded datasets
- Train/test splits ready for ML workflows
- Feature engineering pipeline outputs

## ğŸ”§ Customization

The modular design allows for easy modification:
- **Add new models**: Create new notebook following the established pattern
- **Modify features**: Update `encoding_utils.py` and `data_processor.py`
- **Change evaluation metrics**: Modify `analysis_engine.py`
- **Custom visualizations**: Extend `visualization.py`

## ğŸ“‹ Workflow

1. **Data Ingestion** â†’ Clean and validate raw CSV files
2. **Exploration** â†’ Visual analysis and feature understanding
3. **Preprocessing** â†’ Stratification, encoding, and train/test splits
4. **Modeling** â†’ Train and optimize individual models
5. **Evaluation** â†’ Compare performance across all models
6. **Deployment** â†’ Saved models ready for production use

---

**ğŸ¯ Goal**: Predict student academic outcomes (Withdrawn/Fail/Pass/Distinction) using demographic and engagement data through optimized machine learning models.